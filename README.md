# ğŸŒŠ AquaAI - Sistema Inteligente de GestiÃ³n de Embalses

Sistema avanzado de predicciÃ³n y gestiÃ³n operativa de embalses que combina Deep Learning (LSTM Seq2Seq) con Inteligencia Artificial generativa (Ollama) para proporcionar predicciones precisas y recomendaciones contextualizadas.

## ğŸ¯ DescripciÃ³n

AquaAI es una plataforma completa que integra:

- **PredicciÃ³n temporal**: Modelo LSTM Seq2Seq entrenado con datos histÃ³ricos de niveles de embalses y meteorologÃ­a (AEMET)
- **Recomendaciones inteligentes**: GeneraciÃ³n de recomendaciones operativas usando LLMs (Phi-3.5)
- **Dashboard interactivo**: VisualizaciÃ³n en tiempo real de predicciones, alertas y KPIs
- **AnÃ¡lisis de riesgo**: EvaluaciÃ³n automÃ¡tica de niveles crÃ­ticos (sequÃ­a, desbordamiento)

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  React + Vite + TailwindCSS
â”‚   (Port 5173)   â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API (FastAPI) â”‚  Predicciones + Recomendaciones
â”‚   (Port 8000)   â”‚  
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚       â”‚
     â†“       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQLâ”‚ â”‚  Ollama   â”‚  LLM (Phi-3.5)
â”‚ (8432)  â”‚ â”‚  (11434)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Componentes

Cada componente tiene su propio README con instrucciones especÃ­ficas:

- **[Frontend](frontend/README.md)** - Dashboard web interactivo
- **[API](api/README.md)** - Backend FastAPI con predicciones
- **[Database](data/database/README.md)** - PostgreSQL con Docker
- **[Recomendations](recomendations/README.md)** - Servicio Ollama LLM

## ğŸš€ Inicio RÃ¡pido

### 1. Base de datos

```bash
cd data/database
cp .env.template .env  # Configurar credenciales
docker-compose up -d
```

### 2. API

```bash
cd api
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.template .env  # Configurar variables
python run.py
```

### 3. Frontend

```bash
cd frontend
npm install
cp .env.example .env  # Configurar API_URL
npm run dev
```

### 4. Ollama (Opcional)

```bash
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Descargar modelo
ollama pull phi3.5:latest

# Iniciar servicio
ollama serve
```

Acceder a: **http://localhost:5173**

## âš™ï¸ Variables de ConfiguraciÃ³n Importantes

### API (.env)

| Variable | DescripciÃ³n | Por Defecto |
|----------|-------------|-------------|
| `DB_HOST` | Host PostgreSQL | `localhost` |
| `DB_PORT` | Puerto PostgreSQL | `8432` |
| `DB_NAME` | Nombre base de datos | `aquaia` |
| `ENABLE_LLM_RECOMENDACIONES` | Activar IA | `False` |
| `OLLAMA_URL` | URL servicio Ollama | `http://localhost:11434` |
| `OLLAMA_MODEL` | Modelo LLM | `phi3.5:latest` |
| `MODEL_PATH` | Ruta modelo LSTM | `resources/Training_Aemet/modelo_embalses_aemet.pth` |
| `CORS_ORIGINS` | OrÃ­genes permitidos | `http://localhost:5173` |

### Frontend (.env)

| Variable | DescripciÃ³n | Por Defecto |
|----------|-------------|-------------|
| `VITE_API_URL` | URL del backend | `http://localhost:8000` |

### Database (.env)

| Variable | DescripciÃ³n | Por Defecto |
|----------|-------------|-------------|
| `POSTGRES_USER` | Usuario PostgreSQL | `usr_aquaia` |
| `POSTGRES_PASSWORD` | ContraseÃ±a | *(configurar)* |
| `POSTGRES_PORT` | Puerto externo | `8432` |

## ğŸ“Š CaracterÃ­sticas TÃ©cnicas

### Modelo LSTM

- **Arquitectura**: Encoder-Decoder Seq2Seq
- **Input**: 90 dÃ­as histÃ³ricos (nivel, precipitaciÃ³n, temperatura, caudal)
- **Output**: PredicciÃ³n hasta 180 dÃ­as
- **MÃ©tricas**: MAE, RMSE, RÂ²

### Sistema de Recomendaciones

- **Niveles de riesgo**: ALTO, MODERADO, BAJO, SEQUÃA
- **Umbrales configurables** por embalse
- **CachÃ© inteligente** (6 horas TTL)
- **Fallback automÃ¡tico** si LLM no disponible

### Dashboard

- **VisualizaciÃ³n**: GrÃ¡ficos interactivos (Recharts)
- **SimulaciÃ³n temporal**: Ver datos histÃ³ricos
- **Alertas**: Sistema de notificaciones
- **KPIs**: MÃ©tricas agregadas del sistema

## ğŸ”§ Dependencias Principales

### Backend
- FastAPI 0.115+
- PyTorch 2.5+
- psycopg2-binary
- pandas, numpy
- httpx (cliente Ollama)

### Frontend
- React 18
- TanStack Query
- Recharts
- TailwindCSS

## ğŸ“ Estructura del Proyecto

```
aquaia/
â”œâ”€â”€ api/                    # Backend FastAPI
â”‚   â”œâ”€â”€ services/          # LÃ³gica de negocio
â”‚   â”œâ”€â”€ routers/           # Endpoints REST
â”‚   â”œâ”€â”€ data/              # Acceso a datos
â”‚   â””â”€â”€ resources/         # Modelos entrenados
â”œâ”€â”€ frontend/              # Dashboard React
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/         # Vistas principales
â”‚       â”œâ”€â”€ components/    # Componentes reutilizables
â”‚       â””â”€â”€ services/      # Cliente API
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ database/          # Docker PostgreSQL
â”‚   â””â”€â”€ aemet/            # Scripts datos AEMET
â”œâ”€â”€ training/              # Notebooks entrenamiento
â””â”€â”€ recomendations/        # ConfiguraciÃ³n Ollama
```

## ğŸ” Seguridad

- API Keys configurables
- Rate limiting
- CORS configurable
- Headers de seguridad (HSTS, X-Frame-Options)
- ValidaciÃ³n de inputs con Pydantic

## ğŸ“ˆ Casos de Uso

1. **PredicciÃ³n de niveles**: Anticipar cambios en embalses hasta 6 meses
2. **GestiÃ³n de riesgos**: Detectar situaciones de sequÃ­a o desbordamiento
3. **Recomendaciones operativas**: Acciones sugeridas por IA contextual
4. **AnÃ¡lisis histÃ³rico**: ComparaciÃ³n de tendencias
5. **Dashboard ejecutivo**: KPIs y mÃ©tricas agregadas

## ğŸ‘¥ Contacto

Para mÃ¡s informaciÃ³n sobre el proyecto, consultar la documentaciÃ³n en `/docs` o los READMEs especÃ­ficos de cada componente.
